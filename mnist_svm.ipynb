{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+PhkQv0Zsxa+yhwEAxuGD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteobolner/AML_Basic/blob/master/mnist_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74nVTBCXzz5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime as dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smn8KWYLc0Mc"
      },
      "source": [
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z89hzuJc4g1"
      },
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMRuFjPedLh-"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy import set_printoptions\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcWkto0m8ow6"
      },
      "source": [
        "X[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GeC7xBb9LtY"
      },
      "source": [
        "rescaledX[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujo747l8ILVS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WjJO7KIorP"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(rescaledX, y, test_size=0.15, random_state=42)\n",
        "data = {\"train\": {\"X\": x_train, \"y\": y_train}, \"test\": {\"X\": x_test, \"y\": y_test},}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhoR7lkzRyVo"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAswIOVTqDqR"
      },
      "source": [
        "C -> regularization parameter\n",
        "In practice, the reason that SVMs tend to be resistant to over-fitting, even in cases where the number of attributes is greater than the number of bservations, is that it uses regularization. They key to avoiding over-fitting lies in careful tuning of the regularization parameter, C , and in the case of non-linear SVMs, careful choice of kernel and tuning of the kernel parameters.\n",
        "\n",
        "The SVM is an approximate implementation of a bound on the generalization error, that depends on the margin (essentially the distance from the decision boundary to the nearest pattern from each class), but is independent of the dimensionality of the feature space (which is why using the kernel trick to map the data into a very high dimensional space isn't such a bad idea as it might seem). So in principle SVMs should be highly resistant to over-fitting, but in practice this depends on the careful choice of C\n",
        "\n",
        "and the kernel parameters. Sadly, over-fitting can also occur quite easily when tuning the hyper-parameters as well, which is my main research area, see\n",
        "\n",
        "G. C. Cawley and N. L. C. Talbot, Preventing over-fitting in model selection via Bayesian regularisation of the hyper-parameters, Journal of Machine Learning Research, volume 8, pages 841-861, April 2007. (www)\n",
        "\n",
        "and\n",
        "\n",
        "G. C. Cawley and N. L. C. Talbot, Over-fitting in model selection and subsequent selection bias in performance evaluation, Journal of Machine Learning Research, 2010. Research, vol. 11, pp. 2079-2107, July 2010. (www)\n",
        "\n",
        "Both of those papers use kernel ridge regression, rather than the SVM, but the same problem arises just as easily with SVMs (also similar bounds apply to KRR, so there isn't that much to choose between them in practice). So in a way, SVMs don't really solve the problem of over-fitting, they just shift the problem from model fitting to model selection.\n",
        "\n",
        "It is often a temptation to make life a bit easier for the SVM by performing some sort of feature selection first. This generally makes matters worse, as unlike the SVM, feature selection algorithms tend to exhibit more over-fitting as the number of attributes increases. Unless you want to know which are the informative attributes, it is usually better to skip the feature selection step and just use regularization to avoid over-fitting the data.\n",
        "\n",
        "In short, there is no inherent problem with using an SVM (or other regularised model such as ridge regression, LARS, Lasso, elastic net etc.) on a problem with 120 observations and thousands of attributes, provided the regularisation parameters are tuned properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXpzGPUROuXK"
      },
      "source": [
        "#poly-9 degrees are used with virtual svms (virtualized data)\n",
        "#mnist_classifier = SVC(probability=False, kernel=\"poly\", degree=9, C =2, gamma=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90gYMsY3UOoT"
      },
      "source": [
        "#mnist_classifier = SVC(probability=False, kernel=\"rbf\", C=1, gamma=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owyu2p5CU-2G"
      },
      "source": [
        "examples = len(data[\"train\"][\"X\"])\n",
        "#mnist_classifier.fit(data[\"train\"][\"X\"][:1000], data[\"train\"][\"y\"][:1000])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UMrQ8GQwpzl"
      },
      "source": [
        "#from sklearn import metrics\n",
        "\n",
        "#predicted = mnist_classifier.predict(data[\"test\"][\"X\"])\n",
        "#print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(data[\"test\"][\"y\"], predicted))\n",
        "#print(\"Accuracy: %0.4f\" % metrics.accuracy_score(data[\"test\"][\"y\"], predicted))\n",
        "\n",
        "# try_id = 1\n",
        "#out = clf.predict(data[\"test\"][\"X\"][try_id])  # clf.predict_proba\n",
        "#print(\"out: %s\" % out)\n",
        "#size = int(len(data[\"test\"][\"X\"][try_id]) ** (0.5))\n",
        "#view_image(\n",
        "#    data[\"test\"][\"X\"][try_id].reshape((size, size)), data[\"test\"][\"y\"][try_id]\n",
        "#)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osHtcfefUVZR"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulo8OVLM7kaW"
      },
      "source": [
        "gamma_range = np.outer(np.logspace(-3, 0, 4),np.array([1,5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb26-93z7t6T"
      },
      "source": [
        "gamma_range = gamma_range.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxUhdsRA-uK_"
      },
      "source": [
        "gamma_range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEqBwmWeVvhB"
      },
      "source": [
        "#gamma_range = [0.001, 0.1, 10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OqZMWDc-vNT"
      },
      "source": [
        "C_range = np.outer(np.logspace(-1, 1, 3),np.array([1,5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHrDNbj-yKv"
      },
      "source": [
        "C_range = C_range.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qrEFule-xDc"
      },
      "source": [
        "#C_range = [0.1,1,10] #for testing, less parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akpjTmfA-1T6"
      },
      "source": [
        "parameters = {'kernel':['rbf'], 'C':C_range, 'gamma': gamma_range}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKGR8n--8xS"
      },
      "source": [
        "svm_clsf = svm.SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z39V7rdd_A43"
      },
      "source": [
        "grid_clsf = GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=6, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQZyzYxu_Gls"
      },
      "source": [
        "start_time = dt.datetime.now()\n",
        "print('Start param searching at {}'.format(str(start_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQbDYOzs_I9X"
      },
      "source": [
        "\n",
        "grid_clsf.fit(data[\"train\"][\"X\"][:examples], data[\"train\"][\"y\"][:examples])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUcBeh1Q_P3F"
      },
      "source": [
        "elapsed_time= dt.datetime.now() - start_time\n",
        "print('Elapsed time, param searching {}'.format(str(elapsed_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V37G_LmF_QPB"
      },
      "source": [
        "sorted(grid_clsf.cv_results_.keys())\n",
        "\n",
        "classifier = grid_clsf.best_estimator_\n",
        "params = grid_clsf.best_params_\n",
        "scores = grid_clsf.cv_results_['mean_test_score'].reshape(len(C_range), len(gamma_range))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O08OIwD1B1HQ"
      },
      "source": [
        "grid_clsf.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tow4TA4LS_zX"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "predicted = grid_clsf.predict(data[\"test\"][\"X\"])\n",
        "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(data[\"test\"][\"y\"], predicted))\n",
        "print(\"Accuracy: %0.4f\" % metrics.accuracy_score(data[\"test\"][\"y\"], predicted))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}